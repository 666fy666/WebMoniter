"""iKuuu/SSPanel ikuuuç­¾åˆ°ä»»åŠ¡æ¨¡å—

iKuuu è‡ªåŠ¨ç­¾åˆ°è„šæœ¬ï¼š
- è‡ªåŠ¨ä» ikuuu.club æå–å¯ç”¨åŸŸåï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®åŸŸå/URL
- æ”¯æŒæ¯å¤©å›ºå®šæ—¶é—´ï¼ˆé»˜è®¤ 08:00ï¼‰è‡ªåŠ¨ç­¾åˆ°
- é¡¹ç›®å¯åŠ¨æ—¶ä¹Ÿä¼šæ‰§è¡Œä¸€æ¬¡ç­¾åˆ°
"""

from __future__ import annotations

import asyncio
import base64
import logging
import random
import re
from dataclasses import dataclass
from typing import Any

import aiohttp
from bs4 import BeautifulSoup
from yarl import URL

from src.config import AppConfig, get_config, is_in_quiet_hours, parse_checkin_time
from src.job_registry import register_task
from src.push_channel.manager import UnifiedPushManager, build_push_manager

logger = logging.getLogger(__name__)

# ikuuu åŸŸåå‘ç°å…¥å£
_IKUUU_DISCOVERY_URL = "http://ikuuu.club"

# ikuuu å†å²ä½¿ç”¨è¿‡çš„ TLDï¼ŒæŒ‰é¦–å­—æ¯åˆ†ç»„
# ç”¨äºè§£ææ··æ·† JS ä¸­è¢«æ‹†åˆ†çš„åŸŸåç‰‡æ®µï¼ˆå¦‚ 'uuu.f' + æ··æ·†å‡½æ•°() â†’ ikuuu.fyiï¼‰
_IKUUU_TLD_CANDIDATES: dict[str, list[str]] = {
    "a": ["art"],
    "b": ["bar", "biz"],
    "c": ["co", "com", "cam"],
    "d": ["de", "dev"],
    "e": ["eu"],
    "f": ["fyi", "fun"],
    "g": ["group"],
    "i": ["io"],
    "m": ["me"],
    "n": ["nl", "net"],
    "o": ["one", "org"],
    "p": ["pro"],
    "s": ["site", "store"],
    "t": ["top", "tv"],
    "u": ["us"],
    "w": ["world", "win"],
}


async def _probe_domain(session: aiohttp.ClientSession, domain: str) -> str | None:
    """å°è¯•é€šè¿‡ HTTP HEAD è¯·æ±‚éªŒè¯åŸŸåæ˜¯å¦å¯ç”¨ï¼Œè¿”å›åŸŸåæˆ– Noneã€‚"""
    try:
        async with session.head(
            f"https://{domain}",
            timeout=aiohttp.ClientTimeout(total=5),
            allow_redirects=True,
        ) as resp:
            if resp.status < 500:
                return domain
    except Exception:  # noqa: BLE001
        pass
    return None


async def _extract_ikuuu_domain() -> str | None:
    """ä» ikuuu.club è‡ªåŠ¨æå–å¯ç”¨åŸŸåï¼ˆå¦‚ ikuuu.nlã€ikuuu.fyi ç­‰ï¼‰

    ikuuu.club é¡µé¢ä½¿ç”¨æ··æ·† JS åŠ¨æ€æ¸²æŸ“åŸŸååˆ—è¡¨ï¼ŒåŸŸåä¸åœ¨çº¯æ–‡æœ¬ä¸­ï¼Œ
    è€Œæ˜¯ä»¥å­—ç¬¦ä¸²æ‹¼æ¥æ–¹å¼è—åœ¨ JavaScript æºç é‡Œï¼Œä¾‹å¦‚ï¼š
      'ikuuu' + '.nl'       â†’  å®Œæ•´ TLD å¯ç›´æ¥æå–
      '://ik' + 'uuu.f' + æ··æ·†å‡½æ•°()  â†’  TLD è¢«æ‹†åˆ†ï¼Œåªèƒ½æ‹¿åˆ°é¦–å­—æ¯ 'f'
    å› æ­¤éœ€è¦å¯¹åŸå§‹ HTML æºç åšå¤šç§æ¨¡å¼åŒ¹é…ï¼Œå¯¹äºåªæå–åˆ°é¦–å­—æ¯çš„æƒ…å†µï¼Œ
    é€šè¿‡ HTTP æ¢æµ‹å·²çŸ¥ TLD å€™é€‰åˆ—è¡¨æ¥è¿˜åŸå®Œæ•´åŸŸåã€‚

    æµç¨‹ï¼š
    1. è®¿é—® ikuuu.clubï¼ˆå¯èƒ½é‡å®šå‘æˆ–å±•ç¤ºåŒ…å«æ··æ·† JS çš„åŸŸåé¡µé¢ï¼‰
    2. ä»æœ€ç»ˆ URLã€åŸå§‹ HTML/JS æºç ä¸­æå– ikuuu.xxx æ ¼å¼çš„åŸŸå
    3. å¯¹äºåªæ‹¿åˆ° TLD é¦–å­—æ¯çš„ç‰‡æ®µï¼Œé€šè¿‡ HTTP æ¢æµ‹è¡¥å…¨
    4. éšæœºé€‰æ‹©ä¸€ä¸ªå¯ç”¨åŸŸåè¿”å›
    """
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0"
        )
    }

    try:
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=15)) as session:
            async with session.get(
                _IKUUU_DISCOVERY_URL, headers=headers, allow_redirects=True
            ) as resp:
                raw_html = await resp.text()
                final_url = str(resp.url)

            # â”€â”€ æ”¶é›†æ‰€æœ‰å€™é€‰åŸŸå â”€â”€
            candidates: set[str] = set()

            # 1. ä»é‡å®šå‘åçš„æœ€ç»ˆ URL ä¸­æå–
            redirect_match = re.search(r"ikuuu\.([a-zA-Z]{2,})", final_url)
            if redirect_match:
                candidates.add(f"ikuuu.{redirect_match.group(1)}")

            # 2. ä»åŸå§‹ HTML/JS æºç ä¸­æå–ï¼ˆå…³é”®ï¼šé¡µé¢åŸŸåè—åœ¨æ··æ·† JS é‡Œï¼‰
            #    ç›´æ¥åŒ¹é…ï¼šikuuu.xxxï¼ˆå‡ºç°åœ¨ä»»ä½•ä½ç½®ï¼‰
            for ext in re.findall(r"ikuuu\.([a-zA-Z]{2,})\b", raw_html):
                candidates.add(f"ikuuu.{ext}")

            #    JS å­—ç¬¦ä¸²æ‹¼æ¥æ¨¡å¼ï¼š'ikuuu' + '.nl' æˆ– "ikuuu" + ".nl"
            for ext in re.findall(r"""['"]ikuuu['"]\s*\+\s*['"]\.([a-zA-Z]{2,})""", raw_html):
                candidates.add(f"ikuuu.{ext}")

            #    URL ç‰‡æ®µæ‹¼æ¥æ¨¡å¼ï¼ˆå®Œæ•´ TLDï¼‰ï¼š'uuu.xxx'
            for ext in re.findall(r"""['"]uuu\.([a-zA-Z]{2,})""", raw_html):
                candidates.add(f"ikuuu.{ext}")

            # 3. ä» BeautifulSoup è§£æçš„çº¯æ–‡æœ¬ä¸­æå–
            soup = BeautifulSoup(raw_html, "html.parser")
            text_content = soup.get_text()
            for ext in re.findall(r"ikuuu\.([a-zA-Z]{2,})\b", text_content):
                candidates.add(f"ikuuu.{ext}")

            # 4. ä»é¡µé¢é“¾æ¥ä¸­æå–
            for a_tag in soup.find_all("a", href=True):
                href = a_tag["href"]
                for ext in re.findall(r"ikuuu\.([a-zA-Z]{2,})", href):
                    candidates.add(f"ikuuu.{ext}")

            # â”€â”€ å¤„ç†è¢«æ··æ·† JS æ‹†åˆ†çš„ä¸å®Œæ•´ TLD ç‰‡æ®µ â”€â”€
            # åŒ¹é…å¦‚ 'uuu.f' è¿™æ ·åªæœ‰é¦–å­—æ¯çš„æƒ…å†µï¼ˆååŠè¢«æ··æ·†å‡½æ•°æ‹¼æ¥ï¼‰
            partial_chars: set[str] = set()
            for char in re.findall(r"""['"]uuu\.([a-zA-Z])['"]""", raw_html):
                c = char.lower()
                # è·³è¿‡å·²æœ‰å®Œæ•´åŸŸåä¸­ä»¥è¯¥å­—æ¯å¼€å¤´çš„ TLD
                if not any(d.split(".")[-1].startswith(c) for d in candidates):
                    partial_chars.add(c)

            # å¯¹æ¯ä¸ªä¸å®Œæ•´é¦–å­—æ¯ï¼Œé€šè¿‡ HTTP æ¢æµ‹å·²çŸ¥ TLD å€™é€‰
            if partial_chars:
                probe_tasks = []
                for char in partial_chars:
                    for tld in _IKUUU_TLD_CANDIDATES.get(char, []):
                        probe_tasks.append(_probe_domain(session, f"ikuuu.{tld}"))

                if probe_tasks:
                    results = await asyncio.gather(*probe_tasks, return_exceptions=True)
                    for result in results:
                        if isinstance(result, str):
                            candidates.add(result)
                            logger.debug("ikuuuç­¾åˆ°ï¼šHTTP æ¢æµ‹ç¡®è®¤åŸŸå %s å¯ç”¨", result)

            # æ’é™¤ ikuuu.club æœ¬èº«ï¼ˆè¿™æ˜¯å‘ç°å…¥å£ï¼Œä¸æ˜¯å®é™…æœåŠ¡åŸŸåï¼‰
            candidates.discard("ikuuu.club")

            if candidates:
                selected = random.choice(list(candidates))
                logger.info(
                    "ikuuuç­¾åˆ°ï¼šè‡ªåŠ¨å‘ç°åŸŸå %sï¼ˆå€™é€‰: %sï¼‰",
                    selected,
                    ", ".join(sorted(candidates)),
                )
                return selected

        logger.warning("ikuuuç­¾åˆ°ï¼šæœªèƒ½ä» %s æå–åˆ°å¯ç”¨åŸŸå", _IKUUU_DISCOVERY_URL)
        return None

    except Exception as exc:  # noqa: BLE001
        logger.error("ikuuuç­¾åˆ°ï¼šè‡ªåŠ¨æå–åŸŸåå¤±è´¥ï¼š%s", exc, exc_info=True)
        return None


@dataclass
class CheckinConfig:
    """ç­¾åˆ°ç›¸å…³é…ç½®ï¼ˆå¯è¡¨ç¤ºå•è´¦å·æˆ–ç”¨äºå¤šè´¦å·æ—¶çš„å…¬å…±å­—æ®µï¼‰"""

    enable: bool
    domain: str  # è‡ªåŠ¨å‘ç°çš„åŸŸåï¼Œå¦‚ ikuuu.nl
    email: str
    password: str
    time: str
    accounts: list[dict]  # å¤šè´¦å·åˆ—è¡¨ [{"email": str, "password": str}, ...]ï¼Œæ‰§è¡Œæ—¶ä¼˜å…ˆéå†æ­¤åˆ—è¡¨
    push_channels: list[str]  # æ¨é€é€šé“åç§°åˆ—è¡¨ï¼Œä¸ºç©ºæ—¶ä½¿ç”¨å…¨éƒ¨é€šé“

    @property
    def login_url(self) -> str:
        """ç™»å½•åœ°å€ï¼ˆç”±åŸŸåè‡ªåŠ¨æ„å»ºï¼‰"""
        return f"https://{self.domain}/auth/login"

    @property
    def checkin_url(self) -> str:
        """ç­¾åˆ°æ¥å£åœ°å€ï¼ˆç”±åŸŸåè‡ªåŠ¨æ„å»ºï¼‰"""
        return f"https://{self.domain}/user/checkin"

    @property
    def user_page_url(self) -> str:
        """ç”¨æˆ·ä¿¡æ¯é¡µåœ°å€ï¼ˆç”±åŸŸåè‡ªåŠ¨æ„å»ºï¼‰"""
        return f"https://{self.domain}/user"

    @classmethod
    def from_app_config(cls, config: AppConfig, domain: str) -> CheckinConfig:
        # å¤šè´¦å·ä¼˜å…ˆï¼šcheckin_accounts éç©ºæ—¶ä½¿ç”¨ï¼Œå¦åˆ™ç”¨å•è´¦å·ç»„ä¸€æ¡
        if getattr(config, "checkin_accounts", None):
            accounts = [
                {
                    "email": str(a.get("email", "")).strip(),
                    "password": str(a.get("password", "")).strip(),
                }
                for a in config.checkin_accounts
                if isinstance(a, dict)
            ]
        else:
            accounts = [
                {
                    "email": (config.checkin_email or "").strip(),
                    "password": (config.checkin_password or "").strip(),
                }
            ]
        first = accounts[0] if accounts else {"email": "", "password": ""}
        push_channels: list[str] = getattr(config, "checkin_push_channels", None) or []
        return cls(
            enable=config.checkin_enable,
            domain=domain,
            email=first.get("email", ""),
            password=first.get("password", ""),
            time=config.checkin_time.strip() or "08:00",
            accounts=accounts,
            push_channels=push_channels,
        )

    def with_account(self, email: str, password: str) -> CheckinConfig:
        """è¿”å›ä»…æ›¿æ¢é‚®ç®±/å¯†ç çš„å‰¯æœ¬ï¼Œç”¨äºå•è´¦å·ç™»å½•ä¸æ¨é€ã€‚"""
        return CheckinConfig(
            enable=self.enable,
            domain=self.domain,
            email=email,
            password=password,
            time=self.time,
            accounts=self.accounts,
            push_channels=self.push_channels,
        )

    def validate(self) -> bool:
        """æ ¡éªŒé…ç½®æ˜¯å¦å®Œæ•´"""
        if not self.enable:
            logger.debug("ikuuuç­¾åˆ°æœªå¯ç”¨ï¼Œè·³è¿‡æ‰§è¡Œ")
            return False

        missing_fields: list[str] = []
        if not self.domain:
            missing_fields.append("åŸŸåï¼ˆè‡ªåŠ¨å‘ç°å¤±è´¥ï¼‰")
        if not self.accounts:
            missing_fields.append("checkin.accounts æˆ– checkin.email/password")
        else:
            valid_accounts = [a for a in self.accounts if a.get("email") and a.get("password")]
            if not valid_accounts:
                missing_fields.append("è‡³å°‘ä¸€ä¸ªè´¦å·éœ€åŒ…å« checkin.email ä¸ checkin.password")

        if missing_fields:
            logger.error("ikuuuç­¾åˆ°é…ç½®ä¸å®Œæ•´ï¼Œå·²è·³è¿‡æ‰§è¡Œï¼Œç¼ºå°‘å­—æ®µ: %s", ", ".join(missing_fields))
            return False

        return True


def _mask_email(email: str) -> str:
    """å¯¹é‚®ç®±åšéƒ¨åˆ†è„±æ•ï¼Œç”¨äºæ—¥å¿—è¾“å‡º"""
    if "@" not in email:
        return email
    name, domain = email.split("@", 1)
    if len(name) <= 3:
        masked_name = name[0] + "***" if name else "***"
    else:
        masked_name = name[:3] + "***"
    return f"{masked_name}@{domain}"


async def _login_and_get_cookie(session: aiohttp.ClientSession, cfg: CheckinConfig) -> str | None:
    """ç™»å½•ç«™ç‚¹å¹¶è·å– Cookie"""
    logger.debug("ikuuuç­¾åˆ°ï¼šä½¿ç”¨è´¦å· %s ç™»å½•", _mask_email(cfg.email))

    # ä»ç™»å½•åœ°å€ä¸­æ¨å¯¼å‡ºç«™ç‚¹æ ¹åœ°å€ï¼Œç”¨äºè®¾ç½® Referer / Origin
    try:
        login_url = URL(cfg.login_url)
        base_origin = f"{login_url.scheme}://{login_url.host}"
    except Exception:
        # å¦‚æœ URL è§£æå¤±è´¥ï¼Œåˆ™å›é€€ä¸ºé…ç½®å€¼
        base_origin = cfg.login_url

    headers: dict[str, str] = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0"
        )
    }

    try:
        # è®¿é—®ç™»å½•é¡µï¼Œè·å– CSRF ç­‰å¿…è¦ä¿¡æ¯
        async with session.get(cfg.login_url, headers=headers) as resp:
            text = await resp.text()

        soup = BeautifulSoup(text, "html.parser")
        csrf_token: str | None = None
        csrf_input = soup.find("input", {"name": "_token"})
        if csrf_input:
            csrf_token = csrf_input.get("value")

        login_data: dict[str, str] = {
            "email": cfg.email,
            "passwd": cfg.password,
        }
        if csrf_token:
            login_data["_token"] = csrf_token

        headers.update(
            {
                "Origin": base_origin,
                "Referer": cfg.login_url,
                "Content-Type": "application/x-www-form-urlencoded",
            }
        )

        async with session.post(cfg.login_url, data=login_data, headers=headers) as resp:
            status = resp.status
            resp_url = str(resp.url)

            # ä¼˜å…ˆå°è¯•è§£æ JSON
            json_data: dict[str, Any] | None = None
            try:
                json_data = await resp.json(content_type=None)
            except Exception:
                json_data = None

        if status == 200:
            # 1. ä¸€äº›ç«™ç‚¹ç™»å½•æˆåŠŸä¼šè·³è½¬åˆ° /user ç­‰é¡µé¢
            # 2. æœ‰äº›è¿”å› JSON: {"ret": 1, "msg": "..."}
            if "user" in resp_url or (json_data and json_data.get("ret") == 1):
                logger.debug("ikuuuç­¾åˆ°ï¼šç™»å½•æˆåŠŸ")
                # ä» session ä¸­æå– Cookie
                cookie_jar = session.cookie_jar
                cookies = cookie_jar.filter_cookies(base_origin)
                cookie_string = "; ".join(f"{k}={v.value}" for k, v in cookies.items())
                return cookie_string

            msg = json_data.get("msg") if json_data else "æœªçŸ¥é”™è¯¯"
            logger.error("ikuuuç­¾åˆ°ï¼šç™»å½•å¤±è´¥ï¼š%s", msg)
            return None

        logger.error("ikuuuç­¾åˆ°ï¼šç™»å½•è¯·æ±‚å¤±è´¥ï¼ŒHTTP çŠ¶æ€ç ï¼š%s", status)
        return None

    except Exception as exc:  # noqa: BLE001
        logger.error("ikuuuç­¾åˆ°ï¼šç™»å½•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š%s", exc, exc_info=True)
        return None


async def _checkin(session: aiohttp.ClientSession, cfg: CheckinConfig, cookie: str) -> bool:
    """æ‰§è¡Œç­¾åˆ°"""
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0"
        ),
        "Origin": cfg.checkin_url.rsplit("/user", 1)[0] if "/user" in cfg.checkin_url else "",
        "Referer": (
            cfg.checkin_url.rsplit("/checkin", 1)[0] if "/checkin" in cfg.checkin_url else ""
        ),
        "Cookie": cookie,
    }

    try:
        async with session.post(cfg.checkin_url, headers=headers) as resp:
            try:
                data: dict[str, Any] = await resp.json(content_type=None)
            except Exception as exc:  # noqa: BLE001
                logger.error("ikuuuç­¾åˆ°ï¼šè§£æç­¾åˆ°å“åº”å¤±è´¥ï¼š%s", exc, exc_info=True)
                return False

        msg = data.get("msg", "")
        if data.get("ret") == 1:
            logger.info("ikuuuç­¾åˆ°ï¼šâœ… ç­¾åˆ°æˆåŠŸï¼š%s", msg)
            return True

        if "å·²ç»ç­¾åˆ°" in msg or "å·²ç­¾åˆ°" in msg:
            logger.info("ikuuuç­¾åˆ°ï¼šâ„¹ï¸ ä»Šæ—¥å·²ç­¾åˆ°ï¼š%s", msg)
            return True

        logger.error("ikuuuç­¾åˆ°ï¼šâŒ ç­¾åˆ°å¤±è´¥ï¼š%s", msg)
        return False

    except Exception as exc:  # noqa: BLE001
        logger.error("ikuuuç­¾åˆ°ï¼šç­¾åˆ°è¯·æ±‚å¤±è´¥ï¼š%s", exc, exc_info=True)
        return False


async def _get_user_traffic(
    session: aiohttp.ClientSession, cfg: CheckinConfig, cookie: str
) -> str | None:
    """è·å–å¹¶è¾“å‡ºæµé‡ä¿¡æ¯ï¼Œè¿”å›ç”¨äºæ¨é€çš„æµé‡æ‘˜è¦æ–‡æœ¬ï¼Œå¤±è´¥åˆ™è¿”å› Noneã€‚"""

    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0"
        ),
        "Referer": cfg.user_page_url,
        "Cookie": cookie,
    }

    try:
        async with session.get(cfg.user_page_url, headers=headers) as resp:
            text = await resp.text()

        # éƒ¨åˆ†ç«™ç‚¹å°†æ­£æ–‡æ”¾åœ¨ script çš„ base64(originBody) ä¸­ï¼Œéœ€å…ˆè§£ç å†è§£æ
        html_to_parse = text
        origin_body_match = re.search(
            r'originBody\s*=\s*"([A-Za-z0-9+/=]+)"',
            text,
            re.DOTALL,
        )
        if origin_body_match:
            try:
                decoded = base64.b64decode(origin_body_match.group(1)).decode("utf-8")
                if "card-statistic-2" in decoded or "å‰©ä½™æµé‡" in decoded:
                    html_to_parse = decoded
            except Exception:  # è§£ç å¤±è´¥åˆ™ä»ç”¨åŸå§‹ HTML
                pass

        soup = BeautifulSoup(html_to_parse, "html.parser")

        traffic_cards = soup.find_all("div", class_="card-statistic-2")
        if not traffic_cards:
            logger.debug("ikuuuç­¾åˆ°ï¼šæœªæ‰¾åˆ°æµé‡ç»Ÿè®¡ä¿¡æ¯")
            return None

        lines: list[str] = []
        for card in traffic_cards:
            header = card.find("h4")
            if header and "å‰©ä½™æµé‡" in header.text:
                body = card.find("div", class_="card-body")
                if body:
                    remaining_traffic = re.sub(r"\s+", " ", body.get_text(strip=True))
                    logger.debug("ikuuuç­¾åˆ°ï¼šå‰©ä½™æµé‡ %s", remaining_traffic)
                    lines.append(f"ğŸ“ˆ å‰©ä½™æµé‡ï¼š{remaining_traffic}")

                stats = card.find("div", class_="card-stats-title")
                if stats:
                    today_used_text = re.sub(r"\s+", " ", stats.get_text(strip=True))
                    match = re.search(r":\s*(.+)", today_used_text)
                    if match:
                        today_used = match.group(1).strip()
                        logger.debug("ikuuuç­¾åˆ°ï¼šä»Šæ—¥å·²ç”¨ %s", today_used)
                        lines.append(f"ğŸ“Š ä»Šæ—¥å·²ç”¨ï¼š{today_used}")
                    else:
                        logger.debug("ikuuuç­¾åˆ°ï¼šä»Šæ—¥ä½¿ç”¨ %s", today_used_text)
                        lines.append(f"ğŸ“Š ä»Šæ—¥ä½¿ç”¨æƒ…å†µï¼š{today_used_text}")

        return "\n".join(lines) if lines else None

    except Exception as exc:  # noqa: BLE001
        logger.error("ikuuuç­¾åˆ°ï¼šè·å–æµé‡ä¿¡æ¯å¤±è´¥ï¼š%s", exc, exc_info=True)
        return None


async def run_checkin_once() -> None:
    """æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„ iKuuu/SSPanel ç­¾åˆ°æµç¨‹ï¼ˆæ”¯æŒå¤šè´¦å·ï¼šç™»å½• â†’ ç­¾åˆ° â†’ è·å–æµé‡ä¿¡æ¯ â†’ æ¨é€ï¼‰"""
    app_config = get_config(reload=True)

    if not app_config.checkin_enable:
        logger.debug("ikuuuç­¾åˆ°æœªå¯ç”¨ï¼Œè·³è¿‡æ‰§è¡Œ")
        return

    # è‡ªåŠ¨å‘ç° ikuuu å¯ç”¨åŸŸå
    logger.info("ikuuuç­¾åˆ°ï¼šæ­£åœ¨è‡ªåŠ¨å‘ç°å¯ç”¨åŸŸå...")
    domain = await _extract_ikuuu_domain()
    if not domain:
        logger.error("ikuuuç­¾åˆ°ï¼šæ— æ³•è‡ªåŠ¨å‘ç°å¯ç”¨åŸŸåï¼Œè·³è¿‡æœ¬æ¬¡æ‰§è¡Œ")
        return

    cfg = CheckinConfig.from_app_config(app_config, domain=domain)

    if not cfg.validate():
        return

    valid_accounts = [a for a in cfg.accounts if a.get("email") and a.get("password")]
    logger.info("ikuuuç­¾åˆ°ï¼šå¼€å§‹æ‰§è¡Œï¼ˆå…± %d ä¸ªè´¦å·ï¼‰", len(valid_accounts))

    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=20)) as session:
        push_manager: UnifiedPushManager | None = await build_push_manager(
            app_config.push_channel_list,
            session,
            logger,
            init_fail_prefix="ikuuuç­¾åˆ°ï¼š",
            channel_names=cfg.push_channels if cfg.push_channels else None,
        )
        if push_manager is None:
            logger.warning("ikuuuç­¾åˆ°ï¼šæœªé…ç½®ä»»ä½•æ¨é€é€šé“ï¼Œå°†ä»…åœ¨æ—¥å¿—ä¸­è®°å½•ç»“æœ")

        success_count = 0
        for idx, account in enumerate(valid_accounts):
            cfg_one = cfg.with_account(account["email"], account["password"])
            logger.debug("ikuuuç­¾åˆ°ï¼šæ­£åœ¨å¤„ç†ç¬¬ %d/%d ä¸ªè´¦å·", idx + 1, len(valid_accounts))

            cookie = await _login_and_get_cookie(session, cfg_one)
            if not cookie:
                logger.error("ikuuuç­¾åˆ°ï¼šâŒ è´¦å· %s ç™»å½•å¤±è´¥", _mask_email(cfg_one.email))
                await _send_checkin_push(
                    push_manager,
                    title="ikuuuç­¾åˆ°å¤±è´¥ï¼šç™»å½•å¤±è´¥",
                    msg="ç™»å½•å¤±è´¥ï¼Œæ— æ³•è·å– Cookieï¼Œè¯·æ£€æŸ¥è´¦å·ã€å¯†ç æˆ–ç«™ç‚¹çŠ¶æ€ã€‚",
                    success=False,
                    cfg=cfg_one,
                )
                continue

            ok = await _checkin(session, cfg_one, cookie)
            if ok:
                success_count += 1
            traffic_info = await _get_user_traffic(session, cfg_one, cookie)
            title = "ikuuuç­¾åˆ°æˆåŠŸ" if ok else "ikuuuç­¾åˆ°å¤±è´¥"
            msg = "ç­¾åˆ°æ¥å£è¿”å›æˆåŠŸæˆ–å·²ç­¾åˆ°" if ok else "ç­¾åˆ°æ¥å£è¿”å›å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—è¯¦æƒ…ã€‚"
            await _send_checkin_push(
                push_manager,
                title=title,
                msg=msg,
                success=ok,
                cfg=cfg_one,
                traffic_info=traffic_info,
            )

        if push_manager is not None:
            await push_manager.close()

    logger.info("ikuuuç­¾åˆ°ï¼šç»“æŸï¼ˆæˆåŠŸ %d/%d ä¸ªè´¦å·ï¼‰", success_count, len(valid_accounts))


async def _send_checkin_push(
    push_manager: UnifiedPushManager | None,
    title: str,
    msg: str,
    success: bool,
    cfg: CheckinConfig,
    traffic_info: str | None = None,
) -> None:
    """é€šè¿‡ç»Ÿä¸€æ¨é€é€šé“å‘é€ç­¾åˆ°ç»“æœï¼Œå¯é€‰é™„å¸¦æµé‡ä¿¡æ¯ã€‚"""
    if push_manager is None:
        return

    # å…æ‰“æ‰°æ—¶æ®µå†…åªè®°å½•æ—¥å¿—ï¼Œä¸æ¨é€
    app_cfg = get_config()
    if is_in_quiet_hours(app_cfg):
        logger.debug("ikuuuç­¾åˆ°ï¼šå…æ‰“æ‰°æ—¶æ®µï¼Œä¸å‘é€æ¨é€")
        return

    masked_email = _mask_email(cfg.email)
    status_emoji = "âœ…" if success else "âŒ"
    description = f"{status_emoji} è´¦å·ï¼š{masked_email}\n" f"{msg}\n"
    if traffic_info:
        description += f"\nã€æµé‡ä¿¡æ¯ã€‘\n{traffic_info}\n"
    description += (
        f"\nå½“å‰åŸŸåï¼š{cfg.domain}\n" f"ç™»å½•åœ°å€ï¼š{cfg.login_url}\n" f"ç­¾åˆ°æ¥å£ï¼š{cfg.checkin_url}"
    )

    try:
        await push_manager.send_news(
            title=f"{title}",
            description=description,
            to_url=cfg.user_page_url,
            picurl="https://cn.bing.com/th?id=OHR.DubrovnikHarbor_ZH-CN8590217905_1920x1080.jpg",
            btntxt="æŸ¥çœ‹è´¦æˆ·",
            event_type="checkin_ikuuu",
            event_data={
                "success": success,
                "account": masked_email,
                "message": msg,
                "has_traffic_info": bool(traffic_info),
                "domain": cfg.domain,
            },
        )
    except Exception as exc:  # noqa: BLE001
        logger.error("ikuuuç­¾åˆ°ï¼šå‘é€ç­¾åˆ°ç»“æœæ¨é€å¤±è´¥ï¼š%s", exc, exc_info=True)


def _get_checkin_trigger_kwargs(config: AppConfig) -> dict:
    """ä¾›æ³¨å†Œè¡¨ä¸é…ç½®çƒ­é‡è½½ä½¿ç”¨ã€‚"""
    hour, minute = parse_checkin_time(config.checkin_time)
    return {"minute": minute, "hour": hour}


register_task("ikuuu_checkin", run_checkin_once, _get_checkin_trigger_kwargs)
